{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional RNN bot with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('resources/training_dataset.txt') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sent in data:\n",
    "    sentences.append(sent.strip().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "person1 = []\n",
    "person2 = []\n",
    "for i in range(len(sentences)):\n",
    "    if i%2 == 0:\n",
    "        person1.append(sentences[i])\n",
    "    else:\n",
    "        person2.append(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi'],\n",
       " ['hello'],\n",
       " ['hey'],\n",
       " [\"what's\", 'up'],\n",
       " ['greetings'],\n",
       " ['how', 'are', 'you'],\n",
       " [\"what's\", 'your', 'name'],\n",
       " ['what', 'can', 'you', 'do'],\n",
       " ['when', 'can', 'I', 'check', 'in'],\n",
       " ['when', 'can', 'I', 'check', 'out'],\n",
       " ['who', 'are', 'you'],\n",
       " [\"what's\", 'your', 'address'],\n",
       " [\"what's\", 'your', 'phone', 'number'],\n",
       " ['how', 'can', 'I', 'call', 'you'],\n",
       " ['can', 'you', 'call', 'someone', 'for', 'me'],\n",
       " ['can', 'I', 'talk', 'to', 'someone'],\n",
       " ['how', 'to', 'get', 'to', 'your', 'office'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'get',\n",
       "  'to',\n",
       "  'your',\n",
       "  'office',\n",
       "  'if',\n",
       "  'I',\n",
       "  'come',\n",
       "  'from',\n",
       "  'Bordeaux'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'get',\n",
       "  'to',\n",
       "  'your',\n",
       "  'office',\n",
       "  'if',\n",
       "  'I',\n",
       "  'come',\n",
       "  'from',\n",
       "  'Lyon'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'get',\n",
       "  'to',\n",
       "  'your',\n",
       "  'office',\n",
       "  'if',\n",
       "  'I',\n",
       "  'come',\n",
       "  'from',\n",
       "  'Marseille'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'get',\n",
       "  'to',\n",
       "  'your',\n",
       "  'office',\n",
       "  'if',\n",
       "  'I',\n",
       "  'come',\n",
       "  'from',\n",
       "  'Switzerland'],\n",
       " ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'I', 'come', 'by', 'car'],\n",
       " ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'I', 'come', 'by', 'bike'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'get',\n",
       "  'to',\n",
       "  'your',\n",
       "  'office',\n",
       "  'if',\n",
       "  'I',\n",
       "  'come',\n",
       "  'by',\n",
       "  'motobike'],\n",
       " ['I', 'need', 'to', 'make', 'an', 'appointment'],\n",
       " ['I', 'need', 'to', 'see', 'the', 'doctor'],\n",
       " ['When', 'is', 'the', 'doctor', 'free'],\n",
       " ['I', 'need', 'to', 'renew', 'my', 'prescription'],\n",
       " ['I', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband'],\n",
       " ['My', 'child', 'needs', 'to', 'come', 'in', 'for', 'a', 'check-up']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi'],\n",
       " ['hi'],\n",
       " ['hi'],\n",
       " ['nothing', 'much'],\n",
       " ['greetings'],\n",
       " [\"I'm\", 'doing', 'good'],\n",
       " [\"I'm\", 'nameless'],\n",
       " ['anything', 'that', 'you', 'want'],\n",
       " ['the', 'date', 'specified', 'on', 'your', 'reservation'],\n",
       " ['whenever', 'you', 'want', 'to'],\n",
       " ['I', 'am', 'your', 'little', 'assistant'],\n",
       " ['I', \"don't\", 'have', 'an', 'address'],\n",
       " ['I', \"don't\", 'have', 'phone', 'number', 'either'],\n",
       " ['you',\n",
       "  \"can't\",\n",
       "  'call',\n",
       "  'me,',\n",
       "  'you',\n",
       "  'can',\n",
       "  'only',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'me',\n",
       "  'here'],\n",
       " ['sure,', 'what', 'is', 'their', 'phone', 'number'],\n",
       " ['sure,', \"I'm\", 'getting', 'you', 'someone', 'to', 'talk', 'with', 'you'],\n",
       " ['take',\n",
       "  'the',\n",
       "  'metro',\n",
       "  'and',\n",
       "  'stop',\n",
       "  'at',\n",
       "  'the',\n",
       "  'terminus,',\n",
       "  'we',\n",
       "  'are',\n",
       "  '5mins',\n",
       "  'away',\n",
       "  'from',\n",
       "  'there'],\n",
       " ['you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'the',\n",
       "  'TGV',\n",
       "  'then',\n",
       "  'at',\n",
       "  'Paris',\n",
       "  'Train',\n",
       "  'Station',\n",
       "  'you',\n",
       "  'take',\n",
       "  'the',\n",
       "  'subway'],\n",
       " ['you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'the',\n",
       "  'TGV',\n",
       "  'then',\n",
       "  'at',\n",
       "  'Paris',\n",
       "  'Train',\n",
       "  'Station',\n",
       "  'you',\n",
       "  'take',\n",
       "  'the',\n",
       "  'subway'],\n",
       " ['you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'the',\n",
       "  'TGV',\n",
       "  'then',\n",
       "  'at',\n",
       "  'Paris',\n",
       "  'Train',\n",
       "  'Station',\n",
       "  'you',\n",
       "  'take',\n",
       "  'the',\n",
       "  'subway'],\n",
       " ['you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'the',\n",
       "  'TGV',\n",
       "  'then',\n",
       "  'at',\n",
       "  'Paris',\n",
       "  'Train',\n",
       "  'Station',\n",
       "  'you',\n",
       "  'take',\n",
       "  'the',\n",
       "  'subway'],\n",
       " ['you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'the',\n",
       "  'periph',\n",
       "  'and',\n",
       "  'drive',\n",
       "  'for',\n",
       "  '30mins'],\n",
       " ['you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'the',\n",
       "  'periph',\n",
       "  'and',\n",
       "  'drive',\n",
       "  'for',\n",
       "  '80mins'],\n",
       " ['you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'the',\n",
       "  'periph',\n",
       "  'and',\n",
       "  'drive',\n",
       "  'for',\n",
       "  '40mins'],\n",
       " ['sure,', 'about', 'what'],\n",
       " ['sure,', 'about', 'what'],\n",
       " ['well,', 'depends', 'on', 'how', 'urgent', 'you', 'need', 'him'],\n",
       " ['can', 'you', 'come', 'to', 'the', 'clinic'],\n",
       " ['sure,', 'for', 'what'],\n",
       " ['well,', 'please', 'fill', 'the', 'form', 'below']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "[[words.append(w) for w in sent] for sent in sentences];\n",
    "vocab = list(set(words))\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_to_word = dict(enumerate(vocab))\n",
    "word_to_id = {v:k for k,v in id_to_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_word[vocab_size] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = max([len(s) for s in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(person1)):\n",
    "    person1[i] = [word_to_id[w] for w in person1[i]] + [vocab_size] * (seq_len - len(person1[i]))\n",
    "    person2[i] = [word_to_id[w] for w in person2[i]] + [vocab_size] * (seq_len - len(person2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person1 = np.array(person1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person2 = np.array(person2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = np.zeros((vocab_size+1, vocab_size+1), dtype=np.float64)\n",
    "for i in range(vocab_size+1):\n",
    "    vec[i,i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = output_shape = vocab_size+1\n",
    "hidden_shape = 64\n",
    "learning_rate = 0.001\n",
    "batch_size = person1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.79446102689\n",
      "person1 :  how are you            \n",
      "person2 :  much an take depends we please take their fill bike make need their an bike\n",
      "====================================================\n",
      "person1 :  what's your name            \n",
      "person2 :  much an bike depends we child take depends please bike take need do child bike\n",
      "====================================================\n",
      "person1 :  what can you do           \n",
      "person2 :  much an take reservation we please take their an bike take need depends in 5mins\n",
      "====================================================\n",
      "person1 :  when can I check in          \n",
      "person2 :  much an take depends we please take their fill bike make need their an bike\n",
      "====================================================\n",
      "person1 :  when can I check out          \n",
      "person2 :  much an take depends we please take their fill bike make need their an bike\n",
      "====================================================\n",
      "person1 :  who are you            \n",
      "person2 :  much an bike depends we child take depends please bike take need do child bike\n",
      "====================================================\n",
      "person1 :  what's your address            \n",
      "person2 :  much an bike depends we child take depends please bike take need do child bike\n",
      "====================================================\n",
      "person1 :  what's your phone number           \n",
      "person2 :  much an bike depends we child take depends please bike take need do child bike\n",
      "====================================================\n",
      "person1 :  how can I call you          \n",
      "person2 :  much an take reservation we please take their an bike take need depends in 5mins\n",
      "====================================================\n",
      "person1 :  can you call someone for me         \n",
      "person2 :  much an take reservation we please take their an bike take need depends in 5mins\n",
      "====================================================\n",
      "4.22318573931\n",
      "4.22283754408\n",
      "4.22281103245\n",
      "4.2163410524\n",
      "4.21589026101\n",
      "person1 :  how are you            \n",
      "person2 :                \n",
      "====================================================\n",
      "person1 :  what's your name            \n",
      "person2 :                \n",
      "====================================================\n",
      "person1 :  what can you do           \n",
      "person2 :  you you you            \n",
      "====================================================\n",
      "person1 :  when can I check in          \n",
      "person2 :  you you you            \n",
      "====================================================\n",
      "person1 :  when can I check out          \n",
      "person2 :  you you you            \n",
      "====================================================\n",
      "person1 :  who are you            \n",
      "person2 :  you you you            \n",
      "====================================================\n",
      "person1 :  what's your address            \n",
      "person2 :  you              \n",
      "====================================================\n",
      "person1 :  what's your phone number           \n",
      "person2 :  you              \n",
      "====================================================\n",
      "person1 :  how can I call you          \n",
      "person2 :  you you you you you you  drive       \n",
      "====================================================\n",
      "person1 :  can you call someone for me         \n",
      "person2 :  you              \n",
      "====================================================\n",
      "4.17616846158\n",
      "4.11827802957\n",
      "4.09388673922\n",
      "4.09378603515\n",
      "4.06071278462\n",
      "person1 :  how are you            \n",
      "person2 :   you you            \n",
      "====================================================\n",
      "person1 :  what's your name            \n",
      "person2 :                \n",
      "====================================================\n",
      "person1 :  what can you do           \n",
      "person2 :  you you you you           \n",
      "====================================================\n",
      "person1 :  when can I check in          \n",
      "person2 :   you             \n",
      "====================================================\n",
      "person1 :  when can I check out          \n",
      "person2 :  you you you you           \n",
      "====================================================\n",
      "person1 :  who are you            \n",
      "person2 :   you             \n",
      "====================================================\n",
      "person1 :  what's your address            \n",
      "person2 :   you             \n",
      "====================================================\n",
      "person1 :  what's your phone number           \n",
      "person2 :   you             \n",
      "====================================================\n",
      "person1 :  how can I call you          \n",
      "person2 :  you can't you you you periph can't can't you      \n",
      "====================================================\n",
      "person1 :  can you call someone for me         \n",
      "person2 :   you you            \n",
      "====================================================\n",
      "4.03403294285\n",
      "4.03394284996\n",
      "4.03392464356\n",
      "4.03391526245\n",
      "4.03388172188\n",
      "person1 :  how are you            \n",
      "person2 :  you              \n",
      "====================================================\n",
      "person1 :  what's your name            \n",
      "person2 :  hi              \n",
      "====================================================\n",
      "person1 :  what can you do           \n",
      "person2 :  you you you you           \n",
      "====================================================\n",
      "person1 :  when can I check in          \n",
      "person2 :  can't you can't            \n",
      "====================================================\n",
      "person1 :  when can I check out          \n",
      "person2 :  you you you            \n",
      "====================================================\n",
      "person1 :  who are you            \n",
      "person2 :  you you             \n",
      "====================================================\n",
      "person1 :  what's your address            \n",
      "person2 :  can't you can't            \n",
      "====================================================\n",
      "person1 :  what's your phone number           \n",
      "person2 :  can't you can't            \n",
      "====================================================\n",
      "person1 :  how can I call you          \n",
      "person2 :  you can't you you you periph and can't you      \n",
      "====================================================\n",
      "person1 :  can you call someone for me         \n",
      "person2 :  can't you can't            \n",
      "====================================================\n",
      "4.03386550309\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f1bbcfdd8d06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    209\u001b[0m                             \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mperson2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                             \u001b[0mh_in\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                             c_in: np.zeros((batch_size, hidden_shape*2))})\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shivam/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shivam/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shivam/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/shivam/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shivam/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as graph:\n",
    "    \n",
    "     # placeholders for input and output\n",
    "    X = tf.placeholder(shape=[None,seq_len], dtype=tf.int32, name=\"input\")\n",
    "    Y = tf.placeholder(shape=[None,seq_len], dtype=tf.int32, name=\"target\")\n",
    "    \n",
    "    # embedding tensor\n",
    "    embed = tf.constant(vec, name=\"embeddings\", dtype=tf.float64)\n",
    "    \n",
    "    # input embeddings\n",
    "    X_embed = tf.nn.embedding_lookup(embed, X, name=\"input_embeddings\")\n",
    "    X_embed = tf.transpose(X_embed, perm=[1,0,2])\n",
    "    \n",
    "    # output embeddings\n",
    "    Y_embed = tf.nn.embedding_lookup(embed, Y, name=\"output_embeddings\")\n",
    "    \n",
    "    # initial hidden state\n",
    "    h_in = tf.placeholder(shape=[None, hidden_shape], dtype=tf.float64, name=\"hidden_init\")\n",
    "    \n",
    "    # inital context vector\n",
    "    c_in = tf.placeholder(shape=[None, hidden_shape*2], dtype=tf.float64, name=\"context_init\")\n",
    "    \n",
    "    # RNN Cell\n",
    "    def RNN(x_t, \n",
    "            h_prev, \n",
    "            input_shape=input_shape, \n",
    "            hidden_shape=hidden_shape, \n",
    "            output_shape=output_shape):\n",
    "        with tf.variable_scope('RNN'):\n",
    "            \n",
    "            # RNN input weight\n",
    "            W_xh = tf.get_variable(name=\"W_xh\", shape=[input_shape, hidden_shape], \n",
    "                                   initializer=tf.random_normal_initializer(mean=0.0, \n",
    "                                                                            stddev=0.1), \n",
    "                                   dtype=tf.float64)\n",
    "            \n",
    "            # RNN hidden state weight\n",
    "            W_hh = tf.get_variable(name=\"W_hh\", shape=[hidden_shape, hidden_shape], \n",
    "                                   initializer=tf.random_normal_initializer(mean=0.0, \n",
    "                                                                            stddev=0.1), \n",
    "                                   dtype=tf.float64)\n",
    "            \n",
    "            # RNN output weight\n",
    "            W_yh = tf.get_variable(name=\"W_yh\", shape=[hidden_shape, output_shape], \n",
    "                                   initializer=tf.random_normal_initializer(mean=0.0, \n",
    "                                                                            stddev=0.1), \n",
    "                                   dtype=tf.float64)\n",
    "            \n",
    "            # hidden state\n",
    "            h_t = tf.tanh(tf.matmul(x_t, W_xh) + tf.matmul(h_prev, W_hh))\n",
    "            \n",
    "            # output\n",
    "            y_t = tf.nn.softmax(tf.matmul(h_t, W_yh))\n",
    "            \n",
    "            # reshape hidden state\n",
    "            h_t = tf.reshape(h_t, shape=[-1, hidden_shape])\n",
    "            \n",
    "            y_t = tf.reshape(y_t, shape=[-1, output_shape])\n",
    "            \n",
    "            # return list of hidden state and output\n",
    "            return [h_t, y_t]\n",
    "\n",
    "\n",
    "    # helper function  for encoder\n",
    "    def encoder_helper(h_prev, x_t):\n",
    "        with tf.variable_scope(\"encoder_helper\"):\n",
    "            \n",
    "            # unpack hidden variables of stacked layers\n",
    "            h_prev_1, h_prev_2 = h_prev[0], h_prev[1]\n",
    "            \n",
    "            # pass current input and previous hidden state to RNN Cell of layer 1\n",
    "            with tf.variable_scope(\"encoder_layer_1\"):\n",
    "                h_t_1,y_t_1 = RNN(x_t, h_prev_1)\n",
    "            \n",
    "            # pass current output from layer 1 and previous hidden state to RNN Cell of layer 2\n",
    "            with tf.variable_scope(\"encoder_layer_2\"):\n",
    "                h_t_2, _ = RNN(y_t_1, h_prev_2)\n",
    "            \n",
    "            # return hidden states from both the layers\n",
    "            return [h_t_1, h_t_2]\n",
    "    \n",
    "    def encoder(inputs, h_in):\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            \n",
    "            with tf.variable_scope(\"left_to_right\"):\n",
    "                out_encoder_lr = tf.scan(encoder_helper, \n",
    "                                      inputs, \n",
    "                                      initializer=[h_in, h_in])\n",
    "            \n",
    "            inputs_reversed = tf.reverse(inputs, axis=[0])\n",
    "            \n",
    "            with tf.variable_scope(\"right_to_left\"):\n",
    "                out_encoder_rl = tf.scan(encoder_helper, \n",
    "                                      inputs_reversed, \n",
    "                                      initializer=[h_in, h_in])\n",
    "            \n",
    "            # concatenate the hidden layer outputs for the ultimate layer\n",
    "            out_encoder = tf.concat([out_encoder_lr[-1], out_encoder_rl[-1]], 2)\n",
    "            \n",
    "            # return the hidden layer output for all time step\n",
    "            return out_encoder\n",
    "     \n",
    "    \n",
    "    # helper function for decoder\n",
    "    def decoder_helper(inputs, # a list of previous hidden state and current input i.e. previous output\n",
    "                       x_t): # no use extra variable just to iterate over the decoder\n",
    "        with tf.variable_scope(\"decoder_helper\"):\n",
    "            \n",
    "            # decoder RNN output weight\n",
    "            W_yh = tf.get_variable(name=\"W_yh\", shape=[hidden_shape*4, output_shape], \n",
    "                                   initializer=tf.random_normal_initializer(mean=0.0, \n",
    "                                                                            stddev=0.1), \n",
    "                                   dtype=tf.float64)\n",
    "            \n",
    "            # previous hidden state, previous softmax probabilities and previous one-hot vec\n",
    "            h_prev, y_prev, y_prev_one_hot, c_prev = inputs[0], inputs[1], inputs[2], inputs[3] \n",
    "            \n",
    "            # reshape previous hidden state\n",
    "            h_prev = tf.reshape(h_prev, shape=[-1, hidden_shape*2])\n",
    "            \n",
    "            # reshape previous output\n",
    "            y_prev_one_hot = tf.reshape(y_prev_one_hot, [-1, input_shape])\n",
    "            \n",
    "            # reshape previous context vector\n",
    "            c_prev = tf.reshape(c_prev, shape=[-1, hidden_shape*2])\n",
    "            \n",
    "            # concatenate context vector with input\n",
    "            x_t = tf.concat([c_prev, y_prev_one_hot], axis=1)\n",
    "            \n",
    "            # input to RNN Cell\n",
    "            h_t, y_t = RNN(x_t, h_prev, input_shape=input_shape+hidden_shape*2, hidden_shape=hidden_shape*2)\n",
    "            \n",
    "            # reshape hidden states\n",
    "            H = tf.transpose(hidden_states, perm=[1,0,2])\n",
    "            \n",
    "            # calculate attention score\n",
    "            a_t = tf.matmul(H, tf.expand_dims(h_t, 2))\n",
    "            \n",
    "            alpha_t = tf.nn.softmax(a_t)\n",
    "            \n",
    "            H = tf.transpose(hidden_states, perm=[1,2,0])\n",
    "            \n",
    "            c_t = tf.matmul(H, alpha_t)\n",
    "            \n",
    "            c_t = tf.reshape(c_t, shape=[-1, hidden_shape*2])\n",
    "            \n",
    "            h_new = tf.concat([h_t, c_t], axis=1)\n",
    "            \n",
    "            y_t = tf.nn.softmax(tf.matmul(h_new, W_yh))\n",
    "            \n",
    "            # convert previous output to one hot vectors\n",
    "            y_out = tf.nn.embedding_lookup(embed, tf.argmax(y_t, axis=1))\n",
    "            \n",
    "            # outputs for next time step\n",
    "            outputs = [h_t, y_t, y_out, c_prev]\n",
    "            \n",
    "            return outputs\n",
    "    \n",
    "    def decoder(h_in, x_in, x_in_one_hot, c_in):\n",
    "        with tf.variable_scope('decoder'):\n",
    "            # scan deoder helper\n",
    "            out_decoder = tf.scan(decoder_helper, \n",
    "                                  X_embed, \n",
    "                                  initializer=[h_in, x_in, x_in_one_hot, c_in])\n",
    "            \n",
    "            return out_decoder[1:]\n",
    "    \n",
    "    # thought vector output from encoder\n",
    "    hidden_states = encoder(X_embed, h_in)\n",
    "    \n",
    "    thought_vector = hidden_states[-1]\n",
    "    \n",
    "    # weight to calculate encoder output \n",
    "    W_y = tf.get_variable(name=\"W_y\", shape=[hidden_shape*2, output_shape], \n",
    "                          initializer=tf.random_normal_initializer(mean=0.0, \n",
    "                                                                   stddev=0.1), \n",
    "                          dtype=tf.float64)\n",
    "    \n",
    "    # encoder output\n",
    "    encoder_output = tf.nn.softmax(tf.matmul(thought_vector, W_y))\n",
    "    \n",
    "    # convert previous output to one hot vectors\n",
    "    encoder_output_one_hot = tf.nn.embedding_lookup(embed, tf.argmax(encoder_output, axis=1))\n",
    "    \n",
    "    # send thought vectorm, softmax output vector, one-hot vector and context vector to the decoder\n",
    "    decoder_output, decoder_output_one_hot, _ = decoder(thought_vector, encoder_output, encoder_output_one_hot, c_in)\n",
    "    \n",
    "    seq_output = tf.transpose(decoder_output, perm=[1, 0, 2])\n",
    "    \n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_embed, \n",
    "                                                                      logits=seq_output))\n",
    "    \n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    output = tf.argmax(decoder_output, axis=2)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        \n",
    "        for i in range(20001):\n",
    "            \n",
    "            _,l = sess.run([optimizer, loss], \n",
    "                           {X:person1, \n",
    "                            Y:person2, \n",
    "                            h_in: np.zeros((batch_size, hidden_shape)), \n",
    "                            c_in: np.zeros((batch_size, hidden_shape*2))})\n",
    "            \n",
    "            if i%1000 == 0:\n",
    "                print(l)\n",
    "            \n",
    "            if i%5000 == 0:\n",
    "                pred = sess.run(output, {X:person1, \n",
    "                                         Y:person2, \n",
    "                                         h_in: np.zeros((batch_size, hidden_shape)), \n",
    "                                         c_in: np.zeros((batch_size, hidden_shape*2))})\n",
    "                for j in range(5, 15):\n",
    "                    print(\"person1 : \", ' '.join([[id_to_word[w] for w in sent] for sent in person1][j]))\n",
    "                    print(\"person2 : \", ' '.join([[id_to_word[w] for w in sent] for sent in pred.T][j]))\n",
    "                    print(\"====================================================\")\n",
    "                    \n",
    "        \n",
    "#         out = sess.run(output, {X:a, \n",
    "#                                 Y:person2, \n",
    "#                                 h_in: np.zeros((1, hidden_shape)), \n",
    "#                                 c_in: np.zeros((1, hidden_shape*2))})\n",
    "#         print(\"personA : \", [[id_to_word[w] for w in sent] for sent in a])\n",
    "#         print(\"bot     : \", [[id_to_word[w] for w in sent] for sent in out.T])\n",
    "        writer = tf.summary.FileWriter('tmp/1')\n",
    "        writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'41' on port 6006\n",
      "(You can navigate to http://127.0.1.1:6006)\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "^CTraceback (most recent call last):\n",
      "  File \"/home/shivam/anaconda3/bin/tensorboard\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/shivam/anaconda3/lib/python3.5/site-packages/tensorflow/tensorboard/tensorboard.py\", line 151, in main\n",
      "    tb_server.serve_forever()\n",
      "  File \"/home/shivam/anaconda3/lib/python3.5/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/home/shivam/anaconda3/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir ./tmp/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
